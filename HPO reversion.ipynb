{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This uses a GO parser to parse the HPO obo ontology and then calculates changes made between versions of HPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import with_statement\n",
    "from collections import defaultdict\n",
    "import json\n",
    "import difflib\n",
    "__author__    = \"Uli Koehler\"\n",
    "__copyright__ = \"Copyright 2013 Uli Koehler\"\n",
    "__license__   = \"Apache v2.0\"                                       #this was the original GO parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def processGOTerm(goTerm):\n",
    "    \"\"\"\n",
    "    In an object representing a GO term, replace single-element lists with\n",
    "    their only member.\n",
    "    Returns the modified object as a dictionary.\n",
    "    \"\"\"\n",
    "    ret = dict(goTerm) #Input is a defaultdict, might express unexpected behaviour\n",
    "    for key, value in ret.items():\n",
    "        if len(value) == 1:\n",
    "            ret[key] = value[0]\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parseGOOBO(filename):\n",
    "    \"\"\"\n",
    "    Parses a Gene Ontology dump in OBO v1.2 format.\n",
    "    Yields each \n",
    "    Keyword arguments:\n",
    "        filename: The filename to read\n",
    "    \"\"\"\n",
    "    with open(filename, \"r\", encoding='utf-8') as infile:\n",
    "        currentGOTerm = None\n",
    "        for line in infile:\n",
    "            line = line.strip()\n",
    "            if not line: continue #Skip empty\n",
    "            if line == \"[Term]\":\n",
    "                if currentGOTerm: yield processGOTerm(currentGOTerm)\n",
    "                currentGOTerm = defaultdict(list)\n",
    "            elif line == \"[Typedef]\":\n",
    "                #Skip [Typedef sections]\n",
    "                currentGOTerm = None\n",
    "            else: #Not [Term]\n",
    "                #Only process if we're inside a [Term] environment\n",
    "                if currentGOTerm is None: continue\n",
    "                key, sep, val = line.partition(\":\")\n",
    "                currentGOTerm[key].append(val.strip())\n",
    "        #Add last term\n",
    "        if currentGOTerm is not None:\n",
    "            yield processGOTerm(currentGOTerm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getTerm(searchTerm, HPO):  #find the given id in the parsed ontology HPO\n",
    "    for term in HPO:\n",
    "        if term['id'] == searchTerm:\n",
    "            return(term)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getJson(filename):     #get the json data models\n",
    "    \"\"\"open the JSON file of phenotype models and return it\"\"\"\n",
    "    with open(filename, encoding='utf-8') as data_file:\n",
    "        return json.load(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getParents(term, HPO, HPOtree):         #get the parent tree of a term\n",
    "    try:\n",
    "        parent = getTerm(term, HPO)['is_a']\n",
    "    except:\n",
    "        return\n",
    "    if type(parent) == str:                  #if there is only one parent it is a str\n",
    "        if parent[0:10] == 'HP:0000118':     #if we reach the top of the HPO tree, print the final term and finish\n",
    "            HPOtree.append(parent)\n",
    "            return\n",
    "        else:                          #if we are not at the top of the tree, print the term and recursively get the next parent\n",
    "            HPOtree.append(parent)\n",
    "            getParents(parent[0:10], HPO, HPOtree)\n",
    "    else:                                   #if there is more than one parent (its a list)\n",
    "        for l in parent:                    #go through each term in the list of parents\n",
    "            HPOtree.append(l)                  #print and recursively get the next parent(s)\n",
    "            getParents(l[0:10], HPO, HPOtree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "directory = 'C:/Users/Andrew Devereau/Documents/Python Scripts/'\n",
    "oldFile = directory + 'hpoDMC.obo'   #this is the current DMC HPO version\n",
    "newFile = directory + 'hp060916.obo'  #this is the new HPO version\n",
    "oldHPO = []\n",
    "newHPO = []\n",
    "for goTerm in parseGOOBO(oldFile):\n",
    "    oldHPO.append(goTerm)\n",
    "for goTerm in parseGOOBO(newFile):\n",
    "    newHPO.append(goTerm)\n",
    "print(len(oldHPO))\n",
    "print(len(newHPO))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "keySet = set()                                     #get all of the keys in the ontology. Not all keys are included in each term\n",
    "for node in oldHPO:\n",
    "    for k in node.keys():\n",
    "        keySet.add(k)                              #using a set removes duplicate entries\n",
    "keySet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "modelsJson = getJson(directory + 'Rare Disease Conditions Phenotypes and Clinical Tests - v1.5.1 - FINAL.json')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go through the disease models and find all terms that have changed, been added or removed between the old and new versions of HPO. Write to a text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outfile = open('change.txt', 'w', encoding = 'utf-8')#output file for the change analysis\n",
    "for level2 in modelsJson['DiseaseGroups']:     #run through each model in the json catalogue\n",
    "    for level3 in level2['subGroups']:\n",
    "        for level4 in level3['specificDisorders']:\n",
    "            for pheno in level4['shallowPhenotypes']:  #go through each HPO term\n",
    "                oldTerm = getTerm(pheno['id'], oldHPO)   #for each HPO code get a node from the old and new HPO versions\n",
    "                newTerm = getTerm(pheno['id'], newHPO)\n",
    "                if oldTerm == None:                     #these tests check for terms that are missing from the old and new HPO sets\n",
    "                    outfile.write(level4['id'] + '\\t' + level4['name'] + '\\t' + pheno['id'] + '\\t' + 'Not found in original set' + '\\n')\n",
    "                    continue\n",
    "                if newTerm == None:\n",
    "                    outfile.write(level4['id'] + '\\t' + level4['name'] + '\\t' + pheno['id'] + '\\t' + 'Not found in new set' + '\\n')\n",
    "                    continue\n",
    "                oldKeys = list(oldTerm.keys())           #get a list of the keys in each terms data\n",
    "                newKeys = list(newTerm.keys())\n",
    "                for k in keySet:                               #run through all possible keys for each HPO term\n",
    "                    if k in newTerm and k in oldTerm:           #find fields that have changed\n",
    "                        if newTerm[k] != oldTerm[k]:\n",
    "                            outfile.write(level4['id'] + '\\t' + level4['name'] + '\\t' + pheno['id'] + '\\t' + str(getTerm(pheno['id'], newHPO)['name']))\n",
    "                            outfile.write('\\t' + 'Changed\\t' + k)\n",
    "                            outfile.write('\\t' + str(oldTerm[k]))\n",
    "                            outfile.write('\\t' + str(newTerm[k]) + '\\n')\n",
    "                    elif k in newTerm and k not in oldTerm:     #find fields that have been added\n",
    "                        outfile.write(level4['id'] + '\\t' +  level4['name'] + '\\t' + pheno['id'] + '\\t' + str(getTerm(pheno['id'], newHPO)['name']))\n",
    "                        outfile.write('\\t' + 'Added\\t' + k)\n",
    "                        outfile.write('\\t' + str(newTerm[k])+ '\\n')\n",
    "                    elif k in oldTerm and k not in newTerm:     #find fields that have been removed\n",
    "                        outfile.write(level4['id'] + '\\t' +  level4['name'] + '\\t' + pheno['id'] + '\\t' + str(getTerm(pheno['id'], newHPO)['name']))\n",
    "                        outfile.write('\\t' +'Removed\\t' + k)\n",
    "                        outfile.write('\\t' + str(oldTerm[k])+ '\\n')\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HPOtree1 = []                #this looks for changes to the parent trees of each term\n",
    "HPOtree2 = []\n",
    "for level2 in modelsJson['DiseaseGroups']:     #run through each model in the json catalogue\n",
    "    for level3 in level2['subGroups']:\n",
    "        for level4 in level3['specificDisorders']:\n",
    "            print(level4['name'])             #print the name of disease\n",
    "            for pheno in level4['shallowPhenotypes']:  #go through each HPO term\n",
    "                HPOtree1.clear()\n",
    "                getParents(pheno['id'], newHPO, HPOtree1)  #get the parent tree for new HPO\n",
    "                HPOtree2.clear()\n",
    "                getParents(pheno['id'], oldHPO, HPOtree2)  #get parent tree for old HPO\n",
    "                if HPOtree1 != HPOtree2:           #find differences in trees\n",
    "                    print (pheno['id'], pheno['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HPOtree1=[]\n",
    "HPOtree2=[]\n",
    "getParents('HP:0000252', newHPO, HPOtree1)\n",
    "getParents('HP:0000252', oldHPO, HPOtree2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HPOtree1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HPOtree2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go through all of the HPO terms in the old and new files to find all new and removed terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "oldSet = {term['id'] for term in oldHPO}   #get the set of old HPO ids\n",
    "newSet = {term['id'] for term in newHPO}   #get the set of new HPO ids\n",
    "len(oldSet), len(newSet)                   #get the size of each set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should also check new HPO terms against disease names. These are likely to be core terms so may need to be added to the core terms list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "added = newSet - oldSet    #get the terms added in the new HPO version\n",
    "removed = oldSet - newSet  #get the terms removed from the new HPO version\n",
    "len(added), len(removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for term in removed:\n",
    "    print(term, getTerm(term, oldHPO)['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for term in added:\n",
    "    print(term, getTerm(term, newHPO)['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
